# llm-demo
minimalne rozwiązanie z Ollama + Streamlit, by stworzyć własny model LLM
