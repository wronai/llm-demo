# Modelfile for custom fine-tuned Mistral model
# Generated by convert_to_gguf.sh

FROM ./my_custom_model.gguf

# Model parameters
PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER top_k 40
PARAMETER num_ctx 2048
PARAMETER num_predict 512
PARAMETER repeat_penalty 1.1
PARAMETER repeat_last_n 64

# Stop tokens for Mistral format
PARAMETER stop "<s>"
PARAMETER stop "[INST]"
PARAMETER stop "[/INST]"
PARAMETER stop "</s>"

# System prompt - customize this for your use case
SYSTEM """Jesteś pomocnym asystentem AI stworzonym przez fine-tuning modelu Mistral 7B.

Twoje specjalizacje:
- Programowanie w Pythonie
- Machine Learning i AI
- Docker i DevOps
- Wyjaśnianie technicznych konceptów

Odpowiadasz w języku polskim, jesteś precyzyjny i podajesz praktyczne przykłady.
Gdy nie znasz odpowiedzi, uczciwie to przyznajesz.
"""

# Chat template for Mistral Instruct format
TEMPLATE """<s>{{- if .System }}[INST] {{ .System }}

{{ .Prompt }} [/INST]{{ else }}[INST] {{ .Prompt }} [/INST]{{ end }} {{ .Response }}</s>"""

# Model metadata
PARAMETER num_thread 4
# GPU layers configuration moved to ollama run command