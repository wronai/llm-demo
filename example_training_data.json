[
  {
    "instruction": "Jak zoptymalizowaÄ‡ kod Python dla machine learning?",
    "input": "",
    "output": "Kluczowe optymalizacje dla ML w Pythonie:\n\n1. **Vectoryzacja z NumPy/Pandas**:\n   - Unikaj pÄ™tli Python, uÅ¼ywaj operacji wektorowych\n   - `df.apply()` zamiast iteracji przez wiersze\n\n2. **Wykorzystanie GPU**:\n   - PyTorch/TensorFlow z CUDA\n   - CuPy dla operacji NumPy na GPU\n\n3. **Multiprocessing**:\n   - `multiprocessing.Pool` dla CPU-intensive tasks\n   - `joblib.Parallel` dla sklearn\n\n4. **Memory management**:\n   - `del` niepotrzebnych zmiennych\n   - `gc.collect()` dla garbage collection\n   - Chunking dla duÅ¼ych datasets\n\n5. **Profiling**:\n   - `cProfile` do znajdowania bottleneckÃ³w\n   - `memory_profiler` dla uÅ¼ycia pamiÄ™ci"
  },
  {
    "instruction": "WyjaÅ›nij Docker dla poczÄ…tkujÄ…cych",
    "input": "chcÄ™ zrozumieÄ‡ podstawy",
    "output": "Docker to narzÄ™dzie do konteneryzacji aplikacji. Podstawowe koncepty:\n\n**Co to jest kontener?**\n- Lekka, przenoÅ›na \"paczka\" z aplikacjÄ… i wszystkimi jej zaleÅ¼noÅ›ciami\n- DziaÅ‚a identycznie na kaÅ¼dym systemie\n\n**Podstawowe komendy:**\n```bash\n# Uruchom kontener\ndocker run nginx\n\n# Lista dziaÅ‚ajÄ…cych kontenerÃ³w\ndocker ps\n\n# Zbuduj obraz z Dockerfile\ndocker build -t myapp .\n\n# Zatrzymaj kontener\ndocker stop <container_id>\n```\n\n**Dockerfile przykÅ‚ad:**\n```dockerfile\nFROM python:3.11\nCOPY . /app\nWORKDIR /app\nRUN pip install -r requirements.txt\nCMD [\"python\", \"app.py\"]\n```\n\n**Zalety:**\n- SpÃ³jnoÅ›Ä‡ Å›rodowiska (dev = prod)\n- Åatwe deployowanie\n- Izolacja aplikacji\n- SkalowalnoÅ›Ä‡"
  },
  {
    "instruction": "Jak stworzyÄ‡ REST API w FastAPI?",
    "input": "podstawowy przykÅ‚ad",
    "output": "Oto kompletny przykÅ‚ad REST API w FastAPI:\n\n```python\nfrom fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\nfrom typing import List, Optional\n\napp = FastAPI(title=\"My API\", version=\"1.0.0\")\n\n# Model danych\nclass Item(BaseModel):\n    id: Optional[int] = None\n    name: str\n    price: float\n    description: Optional[str] = None\n\n# \"Baza danych\"\nitems = []\n\n# Endpoints\n@app.get(\"/\")\ndef read_root():\n    return {\"message\": \"Hello World\"}\n\n@app.get(\"/items\", response_model=List[Item])\ndef get_items():\n    return items\n\n@app.get(\"/items/{item_id}\", response_model=Item)\ndef get_item(item_id: int):\n    item = next((x for x in items if x.id == item_id), None)\n    if not item:\n        raise HTTPException(status_code=404, detail=\"Item not found\")\n    return item\n\n@app.post(\"/items\", response_model=Item)\ndef create_item(item: Item):\n    item.id = len(items) + 1\n    items.append(item)\n    return item\n\n@app.put(\"/items/{item_id}\", response_model=Item)\ndef update_item(item_id: int, updated_item: Item):\n    for i, item in enumerate(items):\n        if item.id == item_id:\n            updated_item.id = item_id\n            items[i] = updated_item\n            return updated_item\n    raise HTTPException(status_code=404, detail=\"Item not found\")\n\n@app.delete(\"/items/{item_id}\")\ndef delete_item(item_id: int):\n    global items\n    items = [x for x in items if x.id != item_id]\n    return {\"message\": \"Item deleted\"}\n\n# Uruchomienie\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n```\n\n**Uruchomienie:**\n```bash\npip install fastapi uvicorn\npython main.py\n```\n\n**Automatyczna dokumentacja:**\n- Swagger UI: http://localhost:8000/docs\n- ReDoc: http://localhost:8000/redoc"
  },
  {
    "instruction": "WyjaÅ›nij rÃ³Å¼nice miÄ™dzy AI, ML i Deep Learning",
    "input": "",
    "output": "**Hierarchia pojÄ™Ä‡ (od najszerszego):**\n\nðŸ§  **Artificial Intelligence (AI)**\n- Najszersze pojÄ™cie\n- Systemy zdolne do wykonywania zadaÅ„ wymagajÄ…cych \"inteligencji\"\n- PrzykÅ‚ady: chatboty, systemy eksperckie, algorytmy gier\n\nðŸ¤– **Machine Learning (ML) âŠ‚ AI**\n- PodzbiÃ³r AI\n- Algorytmy uczÄ…ce siÄ™ z danych bez jawnego programowania\n- GÅ‚Ã³wne typy:\n  - **Supervised**: uczenie z etykietowanymi danymi\n  - **Unsupervised**: znajdowanie wzorcÃ³w w danych\n  - **Reinforcement**: uczenie przez nagrody/kary\n\nðŸ§¬ **Deep Learning (DL) âŠ‚ ML**\n- PodzbiÃ³r ML\n- Sieci neuronowe z wieloma warstwami (\"gÅ‚Ä™bokie\")\n- Automatyczne wyodrÄ™bnianie cech z danych\n- PrzykÅ‚ady: CNN (obrazy), RNN (sekwencje), Transformers (tekst)\n\n**Praktyczne rÃ³Å¼nice:**\n\n| Aspekt | AI | ML | Deep Learning |\n|--------|----|----|---------------|\n| **Dane** | ReguÅ‚y+dane | DuÅ¼e zbiory | Bardzo duÅ¼e zbiory |\n| **WydajnoÅ›Ä‡** | ZaleÅ¼na od reguÅ‚ | Dobra | Najlepsza (z danymi) |\n| **Interpretacja** | Jasna | Åšrednia | Trudna (black box) |\n| **Moc obliczeniowa** | Niska | Åšrednia | Wysoka |\n\n**PrzykÅ‚ady:**\n- **AI bez ML**: System ekspercki w medycynie (reguÅ‚y if-then)\n- **ML bez DL**: Drzewo decyzyjne, SVM, regresja\n- **Deep Learning**: GPT, BERT, rozpoznawanie obrazÃ³w"
  },
  {
    "instruction": "Jak debugging w Pythonie?",
    "input": "najlepsze praktyki",
    "output": "**Kompletny guide do debuggingu w Pythonie:**\n\n## 1. **Print debugging (podstawa)**\n```python\n# Klasyczne print\nprint(f\"Zmienna x = {x}, typ: {type(x)}\")\n\n# Lepsze print z kontekstem\nprint(f\"DEBUG [funkcja_name:42]: x={x}\")\n\n# Print z formatowaniem JSON\nimport json\nprint(json.dumps(data, indent=2, ensure_ascii=False))\n```\n\n## 2. **Python Debugger (pdb)**\n```python\n# Wstaw breakpoint\nimport pdb; pdb.set_trace()\n\n# Python 3.7+\nbreakpoint()  # Equivalent do pdb.set_trace()\n\n# Komendy w pdb:\n# n (next line)\n# s (step into)\n# c (continue)\n# l (list code)\n# p variable_name (print variable)\n# pp variable_name (pretty print)\n# q (quit)\n```\n\n## 3. **Logging (profesjonalne)**\n```python\nimport logging\n\n# Konfiguracja\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n\nlogger = logging.getLogger(__name__)\n\n# UÅ¼ycie\nlogger.debug(\"SzczegÃ³Å‚owe info dla debuggingu\")\nlogger.info(\"OgÃ³lne informacje\")\nlogger.warning(\"OstrzeÅ¼enie\")\nlogger.error(\"BÅ‚Ä…d\")\nlogger.critical(\"Krytyczny bÅ‚Ä…d\")\n```\n\n## 4. **IDE Debuggers**\n- **VS Code**: F5 â†’ Run and Debug\n- **PyCharm**: Klik na marginesie â†’ Add Breakpoint\n- **Jupyter**: `%debug` magic command\n\n## 5. **Specialized Tools**\n```python\n# Memory profiling\nfrom memory_profiler import profile\n\n@profile\ndef my_function():\n    # kod do profilowania\n    pass\n\n# Performance profiling\nimport cProfile\ncProfile.run('my_function()')\n\n# Exception debugging\nimport traceback\ntry:\n    risky_code()\nexcept Exception as e:\n    traceback.print_exc()\n    # lub logger.exception(\"Error occurred\")\n```\n\n## 6. **Best Practices**\n- **UÅ¼ywaj assertions**: `assert x > 0, \"x must be positive\"`\n- **Type hints**: Pomaga IDE w debuggingu\n- **Unit testy**: Wczesne wykrywanie bÅ‚Ä™dÃ³w\n- **Linting**: `flake8`, `pylint`, `black`\n- **Exception handling**: Zawsze obsÅ‚uguj wyjÄ…tki\n\n## 7. **Quick Debug Tricks**\n```python\n# Inspect object\nvars(object)  # Wszystkie atrybuty\ndir(object)   # Metody i atrybuty\n\n# Check if variable exists\nif 'variable' in locals():\n    print(variable)\n\n# Pretty print data structures\nfrom pprint import pprint\npprint(complex_dict)\n```"
  },
  {
    "instruction": "Jak zaczÄ…Ä‡ z RTX 3050 i machine learning?",
    "input": "pierwszy projekt",
    "output": "**Kompletny przewodnik ML na RTX 3050:**\n\n## ðŸŽ¯ **Setup Å›rodowiska**\n\n```bash\n# 1. CUDA i cuDNN\n# Pobierz CUDA 11.8 z nvidia.com\n# SprawdÅº: nvidia-smi\n\n# 2. Python environment\nconda create -n ml python=3.10\nconda activate ml\n\n# 3. PyTorch z CUDA\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n\n# 4. ML libraries\npip install pandas numpy matplotlib scikit-learn jupyter\n\n# Test GPU\npython -c \"import torch; print(f'CUDA: {torch.cuda.is_available()}')\"\n```\n\n## ðŸš€ **Pierwszy projekt: Klasyfikacja obrazÃ³w**\n\n```python\nimport torch\nimport torch.nn as nn\nimport torchvision\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\n\n# 1. SprawdÅº GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'Using device: {device}')\n\n# 2. Dataset (CIFAR-10)\ntransform = torchvision.transforms.Compose([\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\ntrain_dataset = torchvision.datasets.CIFAR10(\n    root='./data', train=True, download=True, transform=transform\n)\ntest_dataset = torchvision.datasets.CIFAR10(\n    root='./data', train=False, download=True, transform=transform\n)\n\n# 3. DataLoaders (optymalizowane dla RTX 3050)\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n\n# 4. Prosty CNN model\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n        self.fc2 = nn.Linear(512, 10)\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, x):\n        x = self.pool(torch.relu(self.conv1(x)))\n        x = self.pool(torch.relu(self.conv2(x)))\n        x = x.view(-1, 64 * 8 * 8)\n        x = torch.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n\n# 5. Training setup\nmodel = SimpleCNN().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n# 6. Training loop\nnum_epochs = 5\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    \n    for i, (images, labels) in enumerate(train_loader):\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        \n        if (i+1) % 100 == 0:\n            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}], Loss: {loss.item():.4f}')\n    \n    print(f'Epoch [{epoch+1}] Average Loss: {running_loss/len(train_loader):.4f}')\n\n# 7. Evaluation\nmodel.eval()\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f'Test Accuracy: {100 * correct / total:.2f}%')\n```\n\n## âš¡ **Optymalizacje dla RTX 3050**\n\n```python\n# 1. Mixed Precision Training (oszczÄ™dza VRAM)\nfrom torch.cuda.amp import autocast, GradScaler\n\nscaler = GradScaler()\n\n# W training loop:\nwith autocast():\n    outputs = model(images)\n    loss = criterion(outputs, labels)\n\nscaler.scale(loss).backward()\nscaler.step(optimizer)\nscaler.update()\n\n# 2. Gradient Checkpointing\nmodel.gradient_checkpointing_enable()\n\n# 3. DataLoader optymalizacje\ntrain_loader = DataLoader(\n    dataset, \n    batch_size=32,  # Zmniejsz jeÅ›li brakuje VRAM\n    num_workers=2,  # 2-4 dla RTX 3050\n    pin_memory=True,  # Szybszy transfer CPU->GPU\n    persistent_workers=True  # PyTorch 1.7+\n)\n```\n\n## ðŸ“Š **Monitoring GPU**\n\n```python\n# Memory monitoring\ndef print_gpu_memory():\n    if torch.cuda.is_available():\n        print(f'GPU Memory: {torch.cuda.memory_allocated()/1024**3:.1f}GB / {torch.cuda.max_memory_allocated()/1024**3:.1f}GB')\n        torch.cuda.reset_peak_memory_stats()\n\n# UÅ¼yj po kaÅ¼dej epoce\nprint_gpu_memory()\n```\n\n## ðŸŽ¯ **NastÄ™pne projekty:**\n\n1. **NLP**: Fine-tuning BERT na polskich tekstach\n2. **Computer Vision**: Object detection z YOLO\n3. **Time Series**: Predykcja cen akcji z LSTM\n4. **Generative**: Treninig mini-GAN\n5. **Reinforcement Learning**: Gra w Atari\n\n## ðŸ’¡ **Tips dla RTX 3050:**\n\n- **Batch size**: Zacznij od 32-64, dostosuj do VRAM\n- **Model size**: UÅ¼ywaj mniejszych modeli (ResNet18 zamiast ResNet152)\n- **Mixed precision**: Zawsze wÅ‚Ä…czaj dla wiÄ™kszych modeli\n- **Transfer learning**: UÅ¼ywaj pre-trained modeli zamiast trenowaÄ‡ od zera\n- **Gradient accumulation**: JeÅ›li musisz maÅ‚y batch size\n\n**RTX 3050 = Å›wietna karta do nauki ML! 8GB VRAM wystarczy na wiÄ™kszoÅ›Ä‡ projektÃ³w edukacyjnych.**"
  }
]